---
title: Microsoft デシジョンツリーアルゴリズムテクニカルリファレンス |Microsoft Docs
ms.custom: ''
ms.date: 06/13/2017
ms.prod: sql-server-2014
ms.reviewer: ''
ms.technology: analysis-services
ms.topic: conceptual
helpviewer_keywords:
- MAXIMUM_INPUT_ATTRIBUTES parameter
- SPLIT_METHOD parameter
- MINIMUM_SUPPORT parameter
- MAXIMUM_OUTPUT_ATTRIBUTES parameter
- FORCED_REGRESSOR parameter
- decision tree algorithms [Analysis Services]
- decision trees [Analysis Services]
- COMPLEXITY_PENALTY parameter
- SCORE_METHOD parameter
ms.assetid: 1e9f7969-0aa6-465a-b3ea-57b8d1c7a1fd
author: minewiskan
ms.author: owend
ms.openlocfilehash: 0cd0cd3100d0ed1213183815ae41f17cee3baa68
ms.sourcegitcommit: ad4d92dce894592a259721a1571b1d8736abacdb
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 08/04/2020
ms.locfileid: "87642406"
---
# <a name="microsoft-decision-trees-algorithm-technical-reference"></a><span data-ttu-id="9d469-102">Microsoft デシジョン ツリー アルゴリズム テクニカル リファレンス</span><span class="sxs-lookup"><span data-stu-id="9d469-102">Microsoft Decision Trees Algorithm Technical Reference</span></span>
  <span data-ttu-id="9d469-103">[!INCLUDE[msCoName](../../includes/msconame-md.md)] デシジョン ツリー アルゴリズムは、さまざまなツリー作成手法が組み込まれた複合アルゴリズムであり、回帰、分類、アソシエーションなど、複数の分析タスクをサポートしています。</span><span class="sxs-lookup"><span data-stu-id="9d469-103">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm is a hybrid algorithm that incorporates different methods for creating a tree, and supports multiple analytic tasks, including regression, classification, and association.</span></span> <span data-ttu-id="9d469-104">Microsoft デシジョン ツリー アルゴリズムは、不連続属性と連続属性の両方のモデリングをサポートしています。</span><span class="sxs-lookup"><span data-stu-id="9d469-104">The Microsoft Decision Trees algorithm supports modeling of both discrete and continuous attributes.</span></span>  
  
 <span data-ttu-id="9d469-105">このトピックでは、アルゴリズムの実装について説明し、さまざまなタスクに合わせてアルゴリズムの動作をカスタマイズする方法を示します。また、デシジョン ツリー モデルに対するクエリに関する追加情報へのリンクも示します。</span><span class="sxs-lookup"><span data-stu-id="9d469-105">This topic explains the implementation of the algorithm, describes how to customize the behavior of the algorithm for different tasks, and provides links to additional information about querying decision tree models.</span></span>  
  
## <a name="implementation-of-the-decision-trees-algorithm"></a><span data-ttu-id="9d469-106">デシジョン ツリー アルゴリズムの実装</span><span class="sxs-lookup"><span data-stu-id="9d469-106">Implementation of the Decision Trees Algorithm</span></span>  
 <span data-ttu-id="9d469-107">Microsoft デシジョン ツリー アルゴリズムは、モデルの近似的事後分布を取得して、因果的相互作用のモデルの学習にベイジアン アプローチを適用します。</span><span class="sxs-lookup"><span data-stu-id="9d469-107">The Microsoft Decision Trees algorithm applies the Bayesian approach to learning causal interaction models by obtaining approximate posterior distributions for the models.</span></span> <span data-ttu-id="9d469-108">このアプローチの詳細な説明については、Microsoft Research サイトにある [構造とパラメーターの学習](https://go.microsoft.com/fwlink/?LinkId=237640&clcid=0x409)に関する論文を参照してください。</span><span class="sxs-lookup"><span data-stu-id="9d469-108">For a detailed explanation of this approach, see the paper on the Microsoft Research site, by [Structure and Parameter Learning](https://go.microsoft.com/fwlink/?LinkId=237640&clcid=0x409).</span></span>  
  
 <span data-ttu-id="9d469-109">学習に必要な *事前分布* 情報の価値を評価する手法は、 *尤度等価*の想定に基づいています。</span><span class="sxs-lookup"><span data-stu-id="9d469-109">The methodology for assessing the information value of the *priors* needed for learning is based on the assumption of *likelihood equivalence*.</span></span> <span data-ttu-id="9d469-110">この想定では、条件的に独立した同じアサーションのネットワーク構造は、データでは識別できないものと見なします。</span><span class="sxs-lookup"><span data-stu-id="9d469-110">This assumption says that data should not help to discriminate network structures that otherwise represent the same assertions of conditional independence.</span></span> <span data-ttu-id="9d469-111">各ケースには、ベイジアン事前分布ネットワークと、そのネットワークの信頼メジャーが、それぞれ 1 つずつあるものと見なされます。</span><span class="sxs-lookup"><span data-stu-id="9d469-111">Each case is assumed to have a single Bayesian prior network and a single measure of confidence for that network.</span></span>  
  
 <span data-ttu-id="9d469-112">アルゴリズムでは、これらの事前分布ネットワークを使用して、現在のトレーニング データからネットワーク構造の相対的な *事後確率* を計算し、事後確率が最も高いネットワーク構造を特定します。</span><span class="sxs-lookup"><span data-stu-id="9d469-112">Using these prior networks, the algorithm then computes the relative *posterior probabilities* of network structures given the current training data, and identifies the network structures that have the highest posterior probabilities.</span></span>  
  
 <span data-ttu-id="9d469-113">Microsoft デシジョン ツリー アルゴリズムでは、さまざまな方法を使用して最適なツリーを計算します。</span><span class="sxs-lookup"><span data-stu-id="9d469-113">The Microsoft Decision Trees algorithm uses different methods to compute the best tree.</span></span> <span data-ttu-id="9d469-114">使用される方法はタスクによって異なり、線形回帰、分類、またはアソシエーション分析があります。</span><span class="sxs-lookup"><span data-stu-id="9d469-114">The method used depends on the task, which can be linear regression, classification, or association analysis.</span></span> <span data-ttu-id="9d469-115">個々のモデルには、各種の予測可能な属性に応じて複数のツリーが含まれる可能性があります。</span><span class="sxs-lookup"><span data-stu-id="9d469-115">A single model can contain multiple trees for different predictable attributes.</span></span> <span data-ttu-id="9d469-116">さらに、データ内の属性と値の数に応じて、各ツリーに複数の分岐が含まれる可能性があります。</span><span class="sxs-lookup"><span data-stu-id="9d469-116">Moreover, each tree can contain multiple branches, depending on how many attributes and values there are in the data.</span></span> <span data-ttu-id="9d469-117">特定のモデル内に作成されるツリーの形状と深さは、スコアリング方法と、使用された他のパラメーターによって決まります。</span><span class="sxs-lookup"><span data-stu-id="9d469-117">The shape and depth of the tree built in a particular model depends on the scoring method and other parameters that were used.</span></span> <span data-ttu-id="9d469-118">パラメーターの変更も、ノードの分割場所に影響する可能性があります。</span><span class="sxs-lookup"><span data-stu-id="9d469-118">Changes in the parameters can also affect where the nodes split.</span></span>  
  
### <a name="building-the-tree"></a><span data-ttu-id="9d469-119">ツリーの作成</span><span class="sxs-lookup"><span data-stu-id="9d469-119">Building the Tree</span></span>  
 <span data-ttu-id="9d469-120">Microsoft デシジョン ツリー アルゴリズムは、使用可能な入力値のセットを作成すると *機能の選択* を実行して最も多くの情報を提供する属性と値を特定し、頻度の低い値を考慮対象からはずします。</span><span class="sxs-lookup"><span data-stu-id="9d469-120">When the Microsoft Decision Trees algorithm creates the set of possible input values, it performs *feature selection* to identify the attributes and values that provide the most information, and removes from consideration the values that are very rare.</span></span> <span data-ttu-id="9d469-121">また、このアルゴリズムは、パフォーマンスを最適化するため、値を *ビン*にグループ化し、まとめて処理できる値のグループを作成します。</span><span class="sxs-lookup"><span data-stu-id="9d469-121">The algorithm also groups values into *bins*, to create groupings of values that can be processed as a unit to optimize performance.</span></span>  
  
 <span data-ttu-id="9d469-122">ツリーは、入力と対象の結果との間の相関関係を調べることによって作成されます。</span><span class="sxs-lookup"><span data-stu-id="9d469-122">A tree is built by determining the correlations between an input and the targeted outcome.</span></span> <span data-ttu-id="9d469-123">すべての属性が関連付けられた後、結果を最も明確に区分する 1 つの属性がアルゴリズムによって識別されます。</span><span class="sxs-lookup"><span data-stu-id="9d469-123">After all the attributes have been correlated, the algorithm identifies the single attribute that most cleanly separates the outcomes.</span></span> <span data-ttu-id="9d469-124">この最良の区分点は、情報利得を計算する式を使用して測定されます。</span><span class="sxs-lookup"><span data-stu-id="9d469-124">This point of the best separation is measured by using an equation that calculates information gain.</span></span> <span data-ttu-id="9d469-125">情報利得のスコアが最も高い属性によってケースがサブセットに分割され、次にそのサブセットが同じプロセスで再帰的に分析され、ツリーを分割できなくなるまで繰り返されます。</span><span class="sxs-lookup"><span data-stu-id="9d469-125">The attribute that has the best score for information gain is used to divide the cases into subsets, which are then recursively analyzed by the same process, until the tree cannot be split any more.</span></span>  
  
 <span data-ttu-id="9d469-126">情報利得の評価に使用される正確な式は、アルゴリズムの作成時に設定したパラメーター、予測可能列のデータ型、および入力のデータ型によって異なります。</span><span class="sxs-lookup"><span data-stu-id="9d469-126">The exact equation used to evaluate information gain depends on the parameters set when you created the algorithm, the data type of the predictable column, and the data type of the input.</span></span>  
  
### <a name="discrete-and-continuous-inputs"></a><span data-ttu-id="9d469-127">不連続および連続の入力</span><span class="sxs-lookup"><span data-stu-id="9d469-127">Discrete and Continuous Inputs</span></span>  
 <span data-ttu-id="9d469-128">予測可能属性および入力が不連続の場合、入力あたりの結果をカウントするには、マトリックスを作成し、マトリックスの各セルのスコアを生成します。</span><span class="sxs-lookup"><span data-stu-id="9d469-128">When the predictable attribute is discrete and the inputs are discrete, counting the outcomes per input is a matter of creating a matrix and generating scores for each cell in the matrix.</span></span>  
  
 <span data-ttu-id="9d469-129">ただし、予測可能属性が不連続で入力が連続の場合、連続列の入力が自動的に分離されます。</span><span class="sxs-lookup"><span data-stu-id="9d469-129">However, when the predictable attribute is discrete and the inputs are continuous, the input of the continuous columns are automatically discretized.</span></span> <span data-ttu-id="9d469-130">既定の動作を受け入れると、最適なビン数を [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] で検出できます。また、 <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationMethod%2A> プロパティと <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationBucketCount%2A> プロパティを設定して、連続する入力の分離方法を制御することもできます。</span><span class="sxs-lookup"><span data-stu-id="9d469-130">You can accept the default and have [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] find the optimum number of bins, or you can control the manner in which continuous inputs are discretized by setting the <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationMethod%2A> and <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationBucketCount%2A> properties.</span></span> <span data-ttu-id="9d469-131">詳細については、「 [マイニング モデルでの列の分離の変更](change-the-discretization-of-a-column-in-a-mining-model.md)」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="9d469-131">For more information, see [Change the Discretization of a Column in a Mining Model](change-the-discretization-of-a-column-in-a-mining-model.md).</span></span>  
  
 <span data-ttu-id="9d469-132">連続属性の場合、アルゴリズムでは線型回帰を使用して、デシジョン ツリーの分割ポイントが判断されます。</span><span class="sxs-lookup"><span data-stu-id="9d469-132">For continuous attributes, the algorithm uses linear regression to determine where a decision tree splits.</span></span>  
  
 <span data-ttu-id="9d469-133">予測可能属性が連続する数値データ型の場合、結果数をできるだけ減らしてモデルの作成を高速化するために、機能の選択が出力にも適用されます。</span><span class="sxs-lookup"><span data-stu-id="9d469-133">When the predictable attribute is a continuous numeric data type, feature selection is applied to the outputs as well, to reduce the possible number of outcomes and build the model faster.</span></span> <span data-ttu-id="9d469-134">MAXIMUM_OUTPUT_ATTRIBUTES パラメーターを設定することにより、機能の選択のしきい値を変更して、使用可能な値の数を増減できます。</span><span class="sxs-lookup"><span data-stu-id="9d469-134">You can change the threshold for feature selection and thereby increase or decrease the number of possible values by setting the MAXIMUM_OUTPUT_ATTRIBUTES parameter.</span></span>  
  
 <span data-ttu-id="9d469-135">[!INCLUDE[msCoName](../../includes/msconame-md.md)] デシジョン ツリー アルゴリズムが、不連続の予測可能列をどのように処理するかについては、「 [ベイジアン ネットワークの学習 : 知識と統計データの組み合わせ](https://go.microsoft.com/fwlink/?LinkId=45963)」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="9d469-135">For a more detained explanation about how the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm works with discrete predictable columns, see [Learning Bayesian Networks: The Combination of Knowledge and Statistical Data](https://go.microsoft.com/fwlink/?LinkId=45963).</span></span> <span data-ttu-id="9d469-136">[!INCLUDE[msCoName](../../includes/msconame-md.md)] デシジョン ツリー アルゴリズムが、連続する予測可能列をどのように処理するかについては、「 [時系列分析の自動回帰ツリー モデル](https://go.microsoft.com/fwlink/?LinkId=45966)」の付録を参照してください。</span><span class="sxs-lookup"><span data-stu-id="9d469-136">For more information about how the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm works with a continuous predictable column, see the appendix of [Autoregressive Tree Models for Time-Series Analysis](https://go.microsoft.com/fwlink/?LinkId=45966).</span></span>  
  
### <a name="scoring-methods-and-feature-selection"></a><span data-ttu-id="9d469-137">スコアリング方法と機能の選択</span><span class="sxs-lookup"><span data-stu-id="9d469-137">Scoring Methods and Feature Selection</span></span>  
 <span data-ttu-id="9d469-138">Microsoft デシジョン ツリー アルゴリズムには、情報利得のスコアを計算する式が 3 つ用意されています。Shannon のエントロピー、K2 事前分布を指定したベイジアン ネットワーク、および均一なディリクレ事前分布を指定したベイジアン ネットワークです。</span><span class="sxs-lookup"><span data-stu-id="9d469-138">The Microsoft Decision Trees algorithm offers three formulas for scoring information gain: Shannon's entropy, Bayesian network with K2 prior, and Bayesian network with a uniform Dirichlet distribution of priors.</span></span> <span data-ttu-id="9d469-139">データ マイニング フィールドには、3 つの方法すべてが準備されています。</span><span class="sxs-lookup"><span data-stu-id="9d469-139">All three methods are well established in the data mining field.</span></span> <span data-ttu-id="9d469-140">最適な結果を得るには、複数のパラメーターとスコアリング方法を試してみることをお勧めします。</span><span class="sxs-lookup"><span data-stu-id="9d469-140">We recommend that you experiment with different parameters and scoring methods to determine which provides the best results.</span></span> <span data-ttu-id="9d469-141">これらのスコアリング方法の詳細については、「 [機能の選択](../../sql-server/install/feature-selection.md)」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="9d469-141">For more information about these scoring methods, see [Feature Selection](../../sql-server/install/feature-selection.md).</span></span>  
  
 <span data-ttu-id="9d469-142">すべての [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] データ マイニング アルゴリズムでは、分析の向上と処理負荷の削減のため、機能の選択が自動的に使用されます。</span><span class="sxs-lookup"><span data-stu-id="9d469-142">All [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] data mining algorithms automatically use feature selection to improve analysis and reduce processing load.</span></span> <span data-ttu-id="9d469-143">機能の選択に使用される方法は、モデルの作成に使用したアルゴリズムによって異なります。</span><span class="sxs-lookup"><span data-stu-id="9d469-143">The method used for feature selection depends on the algorithm that is used to build the model.</span></span> <span data-ttu-id="9d469-144">デシジョン ツリー モデルに対する機能の選択を制御するアルゴリズム パラメーターは、MAXIMUM_INPUT_ATTRIBUTES と MAXIMUM_OUTPUT です。</span><span class="sxs-lookup"><span data-stu-id="9d469-144">The algorithm parameters that control feature selection for a decision trees model are MAXIMUM_INPUT_ATTRIBUTES and MAXIMUM_OUTPUT.</span></span>  
  
|<span data-ttu-id="9d469-145">アルゴリズム</span><span class="sxs-lookup"><span data-stu-id="9d469-145">Algorithm</span></span>|<span data-ttu-id="9d469-146">分析の方法</span><span class="sxs-lookup"><span data-stu-id="9d469-146">Method of analysis</span></span>|<span data-ttu-id="9d469-147">説明</span><span class="sxs-lookup"><span data-stu-id="9d469-147">Comments</span></span>|  
|---------------|------------------------|--------------|  
|<span data-ttu-id="9d469-148">デシジョン ツリー</span><span class="sxs-lookup"><span data-stu-id="9d469-148">Decision Trees</span></span>|<span data-ttu-id="9d469-149">興味深さのスコア</span><span class="sxs-lookup"><span data-stu-id="9d469-149">Interestingness score</span></span><br /><br /> <span data-ttu-id="9d469-150">Shannon のエントロピー</span><span class="sxs-lookup"><span data-stu-id="9d469-150">Shannon's Entropy</span></span><br /><br /> <span data-ttu-id="9d469-151">K2 事前分布を指定したベイズ定理</span><span class="sxs-lookup"><span data-stu-id="9d469-151">Bayesian with K2 Prior</span></span><br /><br /> <span data-ttu-id="9d469-152">均一な事前分布を指定したベイズ ディリクレ等式 (既定値)</span><span class="sxs-lookup"><span data-stu-id="9d469-152">Bayesian Dirichlet with uniform prior (default)</span></span>|<span data-ttu-id="9d469-153">非バイナリの連続する値を含む列がある場合は、一貫性を保つため、すべての列に対して興味深さのスコアが使用されます。</span><span class="sxs-lookup"><span data-stu-id="9d469-153">If any columns contain non-binary continuous values, the interestingness score is used for all columns, to ensure consistency.</span></span> <span data-ttu-id="9d469-154">それ以外の場合は、既定の方法か、指定した方法が使用されます。</span><span class="sxs-lookup"><span data-stu-id="9d469-154">Otherwise, the default or specified method is used.</span></span>|  
|<span data-ttu-id="9d469-155">線形回帰</span><span class="sxs-lookup"><span data-stu-id="9d469-155">Linear Regression</span></span>|<span data-ttu-id="9d469-156">興味深さのスコア</span><span class="sxs-lookup"><span data-stu-id="9d469-156">Interestingness score</span></span>|<span data-ttu-id="9d469-157">線形回帰でサポートされるのは連続列だけであるため、興味深さのスコアのみが使用されます。</span><span class="sxs-lookup"><span data-stu-id="9d469-157">Linear Regression only uses interestingness, because it only supports continuous columns.</span></span>|  
  
### <a name="scalability-and-performance"></a><span data-ttu-id="9d469-158">スケーラビリティとパフォーマンス</span><span class="sxs-lookup"><span data-stu-id="9d469-158">Scalability and Performance</span></span>  
 <span data-ttu-id="9d469-159">分類は、重要なデータ マイニング戦略です。</span><span class="sxs-lookup"><span data-stu-id="9d469-159">Classification is an important data mining strategy.</span></span> <span data-ttu-id="9d469-160">一般に、ケースの分類に必要な情報量は、入力レコードの数に正比例して増加します。</span><span class="sxs-lookup"><span data-stu-id="9d469-160">Generally, the amount of information that is needed to classify the cases grows in direct proportion to the number of input records.</span></span> <span data-ttu-id="9d469-161">このため、分類可能なデータのサイズが制限されます。</span><span class="sxs-lookup"><span data-stu-id="9d469-161">This limits the size of the data that can be classified.</span></span> <span data-ttu-id="9d469-162">Microsoft デシジョン ツリー アルゴリズムでは次の方法を使用して、これらの問題を解決し、パフォーマンスを向上させ、メモリの制限を回避します。</span><span class="sxs-lookup"><span data-stu-id="9d469-162">The Microsoft Decision Trees algorithm using uses the following methods to resolve these problems, improve performance, and eliminate memory restrictions:</span></span>  
  
-   <span data-ttu-id="9d469-163">機能の選択で、属性の選択を最適化します。</span><span class="sxs-lookup"><span data-stu-id="9d469-163">Feature selection to optimize the selection of attributes.</span></span>  
  
-   <span data-ttu-id="9d469-164">ベイジアン スコアリングで、ツリーの拡大を制御します。</span><span class="sxs-lookup"><span data-stu-id="9d469-164">Bayesian scoring to control tree growth.</span></span>  
  
-   <span data-ttu-id="9d469-165">連続属性のビン分割を最適化します。</span><span class="sxs-lookup"><span data-stu-id="9d469-165">Optimization of binning for continuous attributes.</span></span>  
  
-   <span data-ttu-id="9d469-166">入力値の動的なグループ化で、最も重要な値を特定します。</span><span class="sxs-lookup"><span data-stu-id="9d469-166">Dynamic grouping of input values to determine the most important values.</span></span>  
  
 <span data-ttu-id="9d469-167">Microsoft デシジョン ツリー アルゴリズムは、高速かつスケーラブルで、簡単に並列処理できるよう設計されています。つまり、すべてのプロセッサが連携し、単一の一貫したモデルを作成します。</span><span class="sxs-lookup"><span data-stu-id="9d469-167">The Microsoft Decision Trees algorithm is fast and scalable, and has been designed to be easily parallelized, meaning that all processors work together to build a single, consistent model.</span></span> <span data-ttu-id="9d469-168">これらの特性を兼ね備えているため、デシジョン ツリー分類子はデータ マイニングに最適のツールです。</span><span class="sxs-lookup"><span data-stu-id="9d469-168">The combination of these characteristics makes the decision-tree classifier an ideal tool for data mining.</span></span>  
  
 <span data-ttu-id="9d469-169">パフォーマンスの制約が大きい場合、次の方法を使用すると、デシジョン ツリー モデルのトレーニング中の処理時間を短縮できる場合があります。</span><span class="sxs-lookup"><span data-stu-id="9d469-169">If performance constraints are severe, you might be able to improve processing time during the training of a decision tree model by using the following methods.</span></span> <span data-ttu-id="9d469-170">ただし、このとき、処理パフォーマンスを向上させるために属性を削除すると、モデルの結果が変わり、母集団を正しく代表しなくなる可能性があります。</span><span class="sxs-lookup"><span data-stu-id="9d469-170">However, if you do so, be aware that eliminating attributes to improve processing performance will change the results of the model, and possibly make it less representative of the total population.</span></span>  
  
-   <span data-ttu-id="9d469-171">ツリーの拡大を制限するには、COMPLEXITY_PENALTY パラメーターの値を大きくします。</span><span class="sxs-lookup"><span data-stu-id="9d469-171">Increase the value of the COMPLEXITY_PENALTY parameter to limit tree growth.</span></span>  
  
-   <span data-ttu-id="9d469-172">作成されるツリー数を制限するには、アソシエーション モデル内のアイテム数を制限します。</span><span class="sxs-lookup"><span data-stu-id="9d469-172">Limit the number of items in association models to limit the number of trees that are built.</span></span>  
  
-   <span data-ttu-id="9d469-173">オーバーフィットを回避するには、MINIMUM_SUPPORT パラメーターの値を大きくします。</span><span class="sxs-lookup"><span data-stu-id="9d469-173">Increase the value of the MINIMUM_SUPPORT parameter to avoid overfitting.</span></span>  
  
-   <span data-ttu-id="9d469-174">任意の属性に対する不連続値の数を、10 以下に制限します。</span><span class="sxs-lookup"><span data-stu-id="9d469-174">Restrict the number of discrete values for any attribute to 10 or less.</span></span> <span data-ttu-id="9d469-175">モデルに応じたさまざまな方法で、値のグループ化を試みることができます。</span><span class="sxs-lookup"><span data-stu-id="9d469-175">You might try grouping values in different ways in different models.</span></span>  
  
    > [!NOTE]  
    >  <span data-ttu-id="9d469-176">[!INCLUDE[ssISCurrent](../../includes/ssiscurrent-md.md)] のデータ探索ツールを使用すると、データ マイニングの開始前に、データ内の値の分布を視覚化し、値を適切にグループ化することができます。</span><span class="sxs-lookup"><span data-stu-id="9d469-176">You can use the data exploration tools available in  [!INCLUDE[ssISCurrent](../../includes/ssiscurrent-md.md)] to visualize the distribution of values in your data and group your values appropriately before beginning data mining.</span></span> <span data-ttu-id="9d469-177">詳細については、「 [データ プロファイル タスクとビューアー](../../integration-services/control-flow/data-profiling-task-and-viewer.md)」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="9d469-177">For more information, see [Data Profiling Task and Viewer](../../integration-services/control-flow/data-profiling-task-and-viewer.md).</span></span> <span data-ttu-id="9d469-178">また、 [Excel 2007 用データ マイニング アドイン](https://www.microsoft.com/download/details.aspx?id=8569)を使用すると、データの探索、グループ化、およびラベル変更を Microsoft Excel で行うことができます。</span><span class="sxs-lookup"><span data-stu-id="9d469-178">You can also use the [Data Mining Add-ins for Excel 2007](https://www.microsoft.com/download/details.aspx?id=8569), to explore, group and relabel data in Microsoft Excel.</span></span>  
  
## <a name="customizing-the-decision-trees-algorithm"></a><span data-ttu-id="9d469-179">デシジョン ツリー アルゴリズムのカスタマイズ</span><span class="sxs-lookup"><span data-stu-id="9d469-179">Customizing the Decision Trees Algorithm</span></span>  
 <span data-ttu-id="9d469-180">[!INCLUDE[msCoName](../../includes/msconame-md.md)] デシジョン ツリー アルゴリズムでは、結果として得られるマイニング モデルのパフォーマンスおよび精度に影響を与えるパラメーターがサポートされています。</span><span class="sxs-lookup"><span data-stu-id="9d469-180">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm supports parameters that affect the performance and accuracy of the resulting mining model.</span></span> <span data-ttu-id="9d469-181">マイニング モデル列またはマイニング構造列にモデリング フラグを設定して、データの処理方法を制御することもできます。</span><span class="sxs-lookup"><span data-stu-id="9d469-181">You can also set modeling flags on the mining model columns or mining structure columns to control the way that data is processed.</span></span>  
  
> [!NOTE]  
>  <span data-ttu-id="9d469-182">Microsoft デシジョン ツリー アルゴリズムは、 [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]のすべてのエディションで利用できます。ただし、Microsoft デシジョン ツリー アルゴリズムの動作をカスタマイズするためのいくつかの高度なパラメーターは、特定のエディションの [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]だけで使用できます。</span><span class="sxs-lookup"><span data-stu-id="9d469-182">The Microsoft Decision Trees algorithm is available in all editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]; however, some advanced parameters for customizing the behavior of the Microsoft Decision Trees algorithm are available for use only in specific editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)].</span></span> <span data-ttu-id="9d469-183">の各エディションでサポートされる機能の一覧につい [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)] ては、「 [SQL Server 2012 の各エディションがサポートする機能](https://go.microsoft.com/fwlink/?linkid=232473)」 (を参照してください https://go.microsoft.com/fwlink/?linkid=232473) 。</span><span class="sxs-lookup"><span data-stu-id="9d469-183">For a list of features that are supported by the editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)], see [Features Supported by the Editions of SQL Server 2012](https://go.microsoft.com/fwlink/?linkid=232473) (https://go.microsoft.com/fwlink/?linkid=232473).</span></span>  
  
### <a name="setting-algorithm-parameters"></a><span data-ttu-id="9d469-184">アルゴリズム パラメーターの設定</span><span class="sxs-lookup"><span data-stu-id="9d469-184">Setting Algorithm Parameters</span></span>  
 <span data-ttu-id="9d469-185">次の表は、 [!INCLUDE[msCoName](../../includes/msconame-md.md)] デシジョン ツリー アルゴリズムで使用できるパラメーターを示しています。</span><span class="sxs-lookup"><span data-stu-id="9d469-185">The following table describes the parameters that you can use with the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm.</span></span>  
  
 <span data-ttu-id="9d469-186">*COMPLEXITY_PENALTY*</span><span class="sxs-lookup"><span data-stu-id="9d469-186">*COMPLEXITY_PENALTY*</span></span>  
 <span data-ttu-id="9d469-187">デシジョン ツリーの拡大を制御します。</span><span class="sxs-lookup"><span data-stu-id="9d469-187">Controls the growth of the decision tree.</span></span> <span data-ttu-id="9d469-188">値を小さくすると分割数が増加し、値を大きくすると分割数が減少します。</span><span class="sxs-lookup"><span data-stu-id="9d469-188">A low value increases the number of splits, and a high value decreases the number of splits.</span></span> <span data-ttu-id="9d469-189">次に示すように、既定値は特定のモデルの属性数に基づいて決定されます。</span><span class="sxs-lookup"><span data-stu-id="9d469-189">The default value is based on the number of attributes for a particular model, as described in the following list:</span></span>  
  
-   <span data-ttu-id="9d469-190">属性数が 1 ～ 9 の場合、既定値は 0.5 です。</span><span class="sxs-lookup"><span data-stu-id="9d469-190">For 1 through 9 attributes, the default is 0.5.</span></span>  
  
-   <span data-ttu-id="9d469-191">属性数が 10 ～ 99 の場合、既定値は 0.9 です。</span><span class="sxs-lookup"><span data-stu-id="9d469-191">For 10 through 99 attributes, the default is 0.9.</span></span>  
  
-   <span data-ttu-id="9d469-192">属性数が 100 以上の場合、既定値は 0.99 です。</span><span class="sxs-lookup"><span data-stu-id="9d469-192">For 100 or more attributes, the default is 0.99.</span></span>  
  
 <span data-ttu-id="9d469-193">*FORCE_REGRESSOR*</span><span class="sxs-lookup"><span data-stu-id="9d469-193">*FORCE_REGRESSOR*</span></span>  
 <span data-ttu-id="9d469-194">アルゴリズムによって計算された列の重要性にかかわらず、指定した列をアルゴリズムでリグレッサーとして使用するように設定します。</span><span class="sxs-lookup"><span data-stu-id="9d469-194">Forces the algorithm to use the specified columns as regressors, regardless of the importance of the columns as calculated by the algorithm.</span></span> <span data-ttu-id="9d469-195">このパラメーターは、連続属性を予測するデシジョン ツリーでのみ使用します。</span><span class="sxs-lookup"><span data-stu-id="9d469-195">This parameter is only used for decision trees that are predicting a continuous attribute.</span></span>  
  
> [!NOTE]  
>  <span data-ttu-id="9d469-196">このパラメーターを設定すると、属性がアルゴリズムのリグレッサーとして使用されます。</span><span class="sxs-lookup"><span data-stu-id="9d469-196">By setting this parameter, you force the algorithm to try to use the attribute as a regressor.</span></span> <span data-ttu-id="9d469-197">ただし、最終的なモデルにおいて属性が実際にリグレッサーとして使用されるかどうかは、分析結果によって決まります。</span><span class="sxs-lookup"><span data-stu-id="9d469-197">However, whether the attribute is actually used as a regressor in the final model depends on the results of analysis.</span></span> <span data-ttu-id="9d469-198">リグレッサーとして使用された列を確認するには、モデル コンテンツに対するクエリを実行します。</span><span class="sxs-lookup"><span data-stu-id="9d469-198">You can find out which columns were used as regressors by querying the model content.</span></span>  
  
 <span data-ttu-id="9d469-199">[一部のエディションの [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)] だけで利用可能]</span><span class="sxs-lookup"><span data-stu-id="9d469-199">[Available only in some editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)] ]</span></span>  
  
 <span data-ttu-id="9d469-200">*MAXIMUM_INPUT_ATTRIBUTES*</span><span class="sxs-lookup"><span data-stu-id="9d469-200">*MAXIMUM_INPUT_ATTRIBUTES*</span></span>  
 <span data-ttu-id="9d469-201">選択した機能を呼び出す前にアルゴリズムが処理できる入力属性の数を定義します。</span><span class="sxs-lookup"><span data-stu-id="9d469-201">Defines the number of input attributes that the algorithm can handle before it invokes feature selection.</span></span>  
  
 <span data-ttu-id="9d469-202">既定値は 255 です。</span><span class="sxs-lookup"><span data-stu-id="9d469-202">The default is 255.</span></span>  
  
 <span data-ttu-id="9d469-203">この値を 0 に設定すると、機能の選択がオフになります。</span><span class="sxs-lookup"><span data-stu-id="9d469-203">Set this value to 0 to turn off feature selection.</span></span>  
  
 <span data-ttu-id="9d469-204">[一部のエディションの [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]だけで利用可能]</span><span class="sxs-lookup"><span data-stu-id="9d469-204">[Available only in some editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]]</span></span>  
  
 <span data-ttu-id="9d469-205">*MAXIMUM_OUTPUT_ATTRIBUTES*</span><span class="sxs-lookup"><span data-stu-id="9d469-205">*MAXIMUM_OUTPUT_ATTRIBUTES*</span></span>  
 <span data-ttu-id="9d469-206">選択した機能を呼び出す前にアルゴリズムが処理できる出力属性の数を定義します。</span><span class="sxs-lookup"><span data-stu-id="9d469-206">Defines the number of output attributes that the algorithm can handle before it invokes feature selection.</span></span>  
  
 <span data-ttu-id="9d469-207">既定値は 255 です。</span><span class="sxs-lookup"><span data-stu-id="9d469-207">The default is 255.</span></span>  
  
 <span data-ttu-id="9d469-208">この値を 0 に設定すると、機能の選択がオフになります。</span><span class="sxs-lookup"><span data-stu-id="9d469-208">Set this value to 0 to turn off feature selection.</span></span>  
  
 <span data-ttu-id="9d469-209">[一部のエディションの [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]だけで利用可能]</span><span class="sxs-lookup"><span data-stu-id="9d469-209">[Available only in some editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]]</span></span>  
  
 <span data-ttu-id="9d469-210">*MINIMUM_SUPPORT*</span><span class="sxs-lookup"><span data-stu-id="9d469-210">*MINIMUM_SUPPORT*</span></span>  
 <span data-ttu-id="9d469-211">デシジョン ツリー内で分割を生成するために必要なリーフ ケースの最小数を決定します。</span><span class="sxs-lookup"><span data-stu-id="9d469-211">Determines the minimum number of leaf cases that is required to generate a split in the decision tree.</span></span>  
  
 <span data-ttu-id="9d469-212">既定値は 10 です。</span><span class="sxs-lookup"><span data-stu-id="9d469-212">The default is 10.</span></span>  
  
 <span data-ttu-id="9d469-213">データセットが非常に大きい場合は、オーバートレーニングを回避するため、この値を大きくする必要が生じることがあります。</span><span class="sxs-lookup"><span data-stu-id="9d469-213">You may need to increase this value if the dataset is very large, to avoid overtraining.</span></span>  
  
 <span data-ttu-id="9d469-214">*SCORE_METHOD*</span><span class="sxs-lookup"><span data-stu-id="9d469-214">*SCORE_METHOD*</span></span>  
 <span data-ttu-id="9d469-215">分割スコアを計算するために使用する方法を決定します。</span><span class="sxs-lookup"><span data-stu-id="9d469-215">Determines the method that is used to calculate the split score.</span></span> <span data-ttu-id="9d469-216">次のオプションを使用できます。</span><span class="sxs-lookup"><span data-stu-id="9d469-216">The following options are available:</span></span>  
  
|<span data-ttu-id="9d469-217">id</span><span class="sxs-lookup"><span data-stu-id="9d469-217">ID</span></span>|<span data-ttu-id="9d469-218">名前</span><span class="sxs-lookup"><span data-stu-id="9d469-218">Name</span></span>|  
|--------|----------|  
|<span data-ttu-id="9d469-219">1</span><span class="sxs-lookup"><span data-stu-id="9d469-219">1</span></span>|<span data-ttu-id="9d469-220">エントロピー</span><span class="sxs-lookup"><span data-stu-id="9d469-220">Entropy</span></span>|  
|<span data-ttu-id="9d469-221">3</span><span class="sxs-lookup"><span data-stu-id="9d469-221">3</span></span>|<span data-ttu-id="9d469-222">K2 事前分布を指定したベイズ定理</span><span class="sxs-lookup"><span data-stu-id="9d469-222">Bayesian with K2 Prior</span></span>|  
|<span data-ttu-id="9d469-223">4</span><span class="sxs-lookup"><span data-stu-id="9d469-223">4</span></span>|<span data-ttu-id="9d469-224">均一な事前分布を指定したベイズ ディリクレ等式 (BDE)</span><span class="sxs-lookup"><span data-stu-id="9d469-224">Bayesian Dirichlet Equivalent (BDE) with uniform prior</span></span><br /><br /> <span data-ttu-id="9d469-225">(既定値)。</span><span class="sxs-lookup"><span data-stu-id="9d469-225">(default)</span></span>|  
  
 <span data-ttu-id="9d469-226">既定値は 4、または BDE です。</span><span class="sxs-lookup"><span data-stu-id="9d469-226">The default is 4, or BDE.</span></span>  
  
 <span data-ttu-id="9d469-227">これらのスコアリング方法の詳細については、「 [機能の選択](../../sql-server/install/feature-selection.md)」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="9d469-227">For an explanation of these scoring methods, see [Feature Selection](../../sql-server/install/feature-selection.md).</span></span>  
  
 <span data-ttu-id="9d469-228">*SPLIT_METHOD*</span><span class="sxs-lookup"><span data-stu-id="9d469-228">*SPLIT_METHOD*</span></span>  
 <span data-ttu-id="9d469-229">ノードを分割するために使用する方法を決定します。</span><span class="sxs-lookup"><span data-stu-id="9d469-229">Determines the method that is used to split the node.</span></span> <span data-ttu-id="9d469-230">次のオプションを使用できます。</span><span class="sxs-lookup"><span data-stu-id="9d469-230">The following options are available:</span></span>  
  
|<span data-ttu-id="9d469-231">id</span><span class="sxs-lookup"><span data-stu-id="9d469-231">ID</span></span>|<span data-ttu-id="9d469-232">名前</span><span class="sxs-lookup"><span data-stu-id="9d469-232">Name</span></span>|  
|--------|----------|  
|<span data-ttu-id="9d469-233">1</span><span class="sxs-lookup"><span data-stu-id="9d469-233">1</span></span>|<span data-ttu-id="9d469-234">**Binary:** 属性値の実際の数にかかわらず、ツリーが 2 つの分岐に分割されることを示します。</span><span class="sxs-lookup"><span data-stu-id="9d469-234">**Binary:** Indicates that regardless of the actual number of values for the attribute, the tree should be split into two branches.</span></span>|  
|<span data-ttu-id="9d469-235">2</span><span class="sxs-lookup"><span data-stu-id="9d469-235">2</span></span>|<span data-ttu-id="9d469-236">**Complete:** 属性値と同じ数の分割をツリーに作成できることを示します。</span><span class="sxs-lookup"><span data-stu-id="9d469-236">**Complete:** Indicates that the tree can create as many splits as there are attribute values.</span></span>|  
|<span data-ttu-id="9d469-237">3</span><span class="sxs-lookup"><span data-stu-id="9d469-237">3</span></span>|<span data-ttu-id="9d469-238">**Both:** バイナリ分割と完全分割のどちらを使用すると最適な結果が生成されるのかが、Analysis Services によって判断されることを示します。</span><span class="sxs-lookup"><span data-stu-id="9d469-238">**Both:** Specifies that Analysis Services can determine whether a binary or complete split should be used to produce the best results.</span></span>|  
  
 <span data-ttu-id="9d469-239">既定値は 3 です。</span><span class="sxs-lookup"><span data-stu-id="9d469-239">The default is 3.</span></span>  
  
### <a name="modeling-flags"></a><span data-ttu-id="9d469-240">ModelingFlags</span><span class="sxs-lookup"><span data-stu-id="9d469-240">Modeling Flags</span></span>  
 <span data-ttu-id="9d469-241">[!INCLUDE[msCoName](../../includes/msconame-md.md)] デシジョン ツリー アルゴリズムでは、次のモデリング フラグがサポートされています。</span><span class="sxs-lookup"><span data-stu-id="9d469-241">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm supports the following modeling flags.</span></span> <span data-ttu-id="9d469-242">モデリング フラグは、マイニング構造やマイニング モデルを作成するときに定義し、分析時に各列の値をどのように処理するかを指定します。</span><span class="sxs-lookup"><span data-stu-id="9d469-242">When you create the mining structure or mining model, you define modeling flags to specify how values in each column are handled during analysis.</span></span> <span data-ttu-id="9d469-243">詳細については、「[モデリング フラグ &#40;データ マイニング&#41;](modeling-flags-data-mining.md)」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="9d469-243">For more information, see [Modeling Flags &#40;Data Mining&#41;](modeling-flags-data-mining.md).</span></span>  
  
|<span data-ttu-id="9d469-244">モデリング フラグ</span><span class="sxs-lookup"><span data-stu-id="9d469-244">Modeling Flag</span></span>|<span data-ttu-id="9d469-245">説明</span><span class="sxs-lookup"><span data-stu-id="9d469-245">Description</span></span>|  
|-------------------|-----------------|  
|<span data-ttu-id="9d469-246">MODEL_EXISTENCE_ONLY</span><span class="sxs-lookup"><span data-stu-id="9d469-246">MODEL_EXISTENCE_ONLY</span></span>|<span data-ttu-id="9d469-247">列が、`Missing` および `Existing` の 2 つの可能な状態を持つ列として扱われることを示します。</span><span class="sxs-lookup"><span data-stu-id="9d469-247">Means that the column will be treated as having two possible states: `Missing` and `Existing`.</span></span> <span data-ttu-id="9d469-248">NULL は Missing 値になります。</span><span class="sxs-lookup"><span data-stu-id="9d469-248">A null is a missing value.</span></span><br /><br /> <span data-ttu-id="9d469-249">マイニング モデル列に適用されます。</span><span class="sxs-lookup"><span data-stu-id="9d469-249">Applies to mining model columns.</span></span>|  
|<span data-ttu-id="9d469-250">NOT NULL</span><span class="sxs-lookup"><span data-stu-id="9d469-250">NOT NULL</span></span>|<span data-ttu-id="9d469-251">列に NULL を含めることはできないことを示します。</span><span class="sxs-lookup"><span data-stu-id="9d469-251">Indicates that the column cannot contain a null.</span></span> <span data-ttu-id="9d469-252">モデルのトレーニング中に NULL が検出された場合はエラーが発生します。</span><span class="sxs-lookup"><span data-stu-id="9d469-252">An error will result if Analysis Services encounters a null during model training.</span></span><br /><br /> <span data-ttu-id="9d469-253">マイニング構造列に適用されます。</span><span class="sxs-lookup"><span data-stu-id="9d469-253">Applies to mining structure columns.</span></span>|  
  
### <a name="regressors-in-decision-tree-models"></a><span data-ttu-id="9d469-254">デシジョン ツリー モデルのリグレッサー</span><span class="sxs-lookup"><span data-stu-id="9d469-254">Regressors in Decision Tree Models</span></span>  
 <span data-ttu-id="9d469-255">[!INCLUDE[msCoName](../../includes/msconame-md.md)] 線形回帰アルゴリズムを使用していない場合でも、連続属性の回帰を表すノードが、連続する数値の入出力を持つデシジョン ツリー モデルに含まれることがあります。</span><span class="sxs-lookup"><span data-stu-id="9d469-255">Even if you do not use the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Linear Regression algorithm, any decision tree model that has continuous numeric inputs and outputs can potentially include nodes that represent a regression on a continuous attribute.</span></span>  
  
 <span data-ttu-id="9d469-256">連続する数値データ列がリグレッサーを表すことを指定する必要はありません。</span><span class="sxs-lookup"><span data-stu-id="9d469-256">You do not need to specify that a column of continuous numeric data represents a regressor.</span></span> <span data-ttu-id="9d469-257">列に REGRESSOR フラグを設定しなくても、 [!INCLUDE[msCoName](../../includes/msconame-md.md)] デシジョン ツリー アルゴリズムにより、列が自動的にリグレッサー候補として使用され、データセットが意味のあるパターンを持つ領域に分割されます。</span><span class="sxs-lookup"><span data-stu-id="9d469-257">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm will automatically use the column as a potential regressor and partition the dataset into regions with meaningful patterns even if you do not set the REGRESSOR flag on the column.</span></span>  
  
 <span data-ttu-id="9d469-258">しかし、FORCE_REGRESSOR パラメーターを使用すると、アルゴリズムで特定のリグレッサーが使用されるようにすることができます。</span><span class="sxs-lookup"><span data-stu-id="9d469-258">However, you can use the FORCE_REGRESSOR parameter to guarantee that the algorithm will use a particular regressor.</span></span> <span data-ttu-id="9d469-259">このパラメーターは、 [!INCLUDE[msCoName](../../includes/msconame-md.md)] デシジョン ツリー アルゴリズムと [!INCLUDE[msCoName](../../includes/msconame-md.md)] 線形回帰アルゴリズムでのみ使用できます。</span><span class="sxs-lookup"><span data-stu-id="9d469-259">This parameter can be used only with the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees and [!INCLUDE[msCoName](../../includes/msconame-md.md)] Linear Regression algorithms.</span></span> <span data-ttu-id="9d469-260">モデリングフラグを設定すると、アルゴリズムによって、\* C1 + b \* C2 +... という形式の回帰式が検索されます。は、ツリーのノードのパターンに適合します。</span><span class="sxs-lookup"><span data-stu-id="9d469-260">When you set the modeling flag, the algorithm will try to find regression equations of the form a\*C1 + b\*C2 + ... to fit the patterns in the nodes of the tree.</span></span> <span data-ttu-id="9d469-261">残差の合計が計算され、偏差が大きすぎる場合には、ツリーが強制的に分割されます。</span><span class="sxs-lookup"><span data-stu-id="9d469-261">The sum of the residuals is calculated, and if the deviation is too great, a split is forced in the tree.</span></span>  
  
 <span data-ttu-id="9d469-262">たとえば、 **Income** を属性として使用して顧客の購入行動を予測する場合に、その列に REGRESSOR モデリング フラグを設定すると、アルゴリズムはまず、標準の回帰式を使用して **Income** の値を試します。</span><span class="sxs-lookup"><span data-stu-id="9d469-262">For example, if you are predicting customer purchasing behavior using **Income** as an attribute, and set the REGRESSOR modeling flag on the column, the algorithm will first try to fit the **Income** values by using a standard regression formula.</span></span> <span data-ttu-id="9d469-263">偏差が大きすぎる場合はその回帰式が放棄され、ツリーが他の属性で分割されます。</span><span class="sxs-lookup"><span data-stu-id="9d469-263">If the deviation is too great, the regression formula is abandoned and the tree will be split on another attribute.</span></span> <span data-ttu-id="9d469-264">その後デシジョン ツリー アルゴリズムは、分割後の各分岐で、Income をリグレッサーとして使用できるかどうかを試します。</span><span class="sxs-lookup"><span data-stu-id="9d469-264">The decision tree algorithm will then try to fit a regressor for income in each of the branches after the split.</span></span>  
  
## <a name="requirements"></a><span data-ttu-id="9d469-265">必要条件</span><span class="sxs-lookup"><span data-stu-id="9d469-265">Requirements</span></span>  
 <span data-ttu-id="9d469-266">デシジョン ツリー モデルには、キー列、入力列、および少なくとも 1 つの予測可能列が必要です。</span><span class="sxs-lookup"><span data-stu-id="9d469-266">A decision tree model must contain a key column, input columns, and at least one predictable column.</span></span>  
  
### <a name="input-and-predictable-columns"></a><span data-ttu-id="9d469-267">入力列と予測可能列</span><span class="sxs-lookup"><span data-stu-id="9d469-267">Input and Predictable Columns</span></span>  
 <span data-ttu-id="9d469-268">[!INCLUDE[msCoName](../../includes/msconame-md.md)] デシジョン ツリー アルゴリズムでは、次の表に示す特定の入力列と予測可能列がサポートされています。</span><span class="sxs-lookup"><span data-stu-id="9d469-268">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm supports the specific input columns and predictable columns that are listed in the following table.</span></span> <span data-ttu-id="9d469-269">マイニング モデルにおけるコンテンツの種類の意味については、「[コンテンツの種類 &#40;データ マイニング&#41;](content-types-data-mining.md)」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="9d469-269">For more information about what the content types mean when used in a mining model, see [Content Types &#40;Data Mining&#41;](content-types-data-mining.md).</span></span>  
  
|<span data-ttu-id="9d469-270">列</span><span class="sxs-lookup"><span data-stu-id="9d469-270">Column</span></span>|<span data-ttu-id="9d469-271">コンテンツの種類</span><span class="sxs-lookup"><span data-stu-id="9d469-271">Content types</span></span>|  
|------------|-------------------|  
|<span data-ttu-id="9d469-272">入力属性</span><span class="sxs-lookup"><span data-stu-id="9d469-272">Input attribute</span></span>|<span data-ttu-id="9d469-273">Continuous、Cyclical、Discrete、Discretized、Key、Ordered、Table</span><span class="sxs-lookup"><span data-stu-id="9d469-273">Continuous, Cyclical, Discrete, Discretized, Key, Ordered, Table</span></span>|  
|<span data-ttu-id="9d469-274">予測可能な属性</span><span class="sxs-lookup"><span data-stu-id="9d469-274">Predictable attribute</span></span>|<span data-ttu-id="9d469-275">Continuous、Cyclical、Discrete、Discretized、Ordered、Table</span><span class="sxs-lookup"><span data-stu-id="9d469-275">Continuous, Cyclical, Discrete, Discretized, Ordered, Table</span></span>|  
  
> [!NOTE]  
>  <span data-ttu-id="9d469-276">コンテンツの種類 Cyclical および Ordered はサポートされますが、アルゴリズムはこれらを不連続の値として扱い、特別な処理は行いません。</span><span class="sxs-lookup"><span data-stu-id="9d469-276">Cyclical and Ordered content types are supported, but the algorithm treats them as discrete values and does not perform special processing.</span></span>  
  
## <a name="see-also"></a><span data-ttu-id="9d469-277">参照</span><span class="sxs-lookup"><span data-stu-id="9d469-277">See Also</span></span>  
 <span data-ttu-id="9d469-278">[Microsoft デシジョンツリーアルゴリズム](microsoft-decision-trees-algorithm.md) </span><span class="sxs-lookup"><span data-stu-id="9d469-278">[Microsoft Decision Trees Algorithm](microsoft-decision-trees-algorithm.md) </span></span>  
 <span data-ttu-id="9d469-279">[デシジョンツリーモデルのクエリ例](decision-trees-model-query-examples.md) </span><span class="sxs-lookup"><span data-stu-id="9d469-279">[Decision Trees Model Query Examples](decision-trees-model-query-examples.md) </span></span>  
 [<span data-ttu-id="9d469-280">デシジョン ツリー モデルのマイニング モデル コンテンツ (Analysis Services - データ マイニング)</span><span class="sxs-lookup"><span data-stu-id="9d469-280">Mining Model Content for Decision Tree Models &#40;Analysis Services - Data Mining&#41;</span></span>](mining-model-content-for-decision-tree-models-analysis-services-data-mining.md)  
  
  
